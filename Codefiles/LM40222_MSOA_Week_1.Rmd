---
title: 'Workshop One: An introduction to R and RStudio'
subtitle: 'Week 1'
output: html_notebook
---
### **Introduction**
This workshop will (eventually!) use UK Census data (from 2021) for the City of Birmingham located on the NONMIS data portal. This website  stores a large number of sources of data within the UK (employment, economic, census and so on). You can access this for yourself using this website link:

https://www.nomisweb.co.uk/ 

To ease you into the process I have download a run of datasets from the Census of 2021. The spatial grain size of the data is at the Middle layer Super Output Areas (MSOAs). These are made up of groups of Lower layer Super Output Areas (LSOAs), usually four or five. They comprise between 2,000 and 6,000 households and have a usually resident population between 5,000 and 15,000 persons.

![Figure 1: MSOAs in Birmingham](/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Images/Birmingham_MSOAs.png)
The next few workshops in this module will these data as a case study. As the module progresses we will use datasets provided by human geography colleagues. The data are stored in a zipfile and downloadable using the following link from my github repository:

(Jon to add in the link)

Download it to a place on your hard disk or shared network drive, OneDrive or some other suitable place. Double click on the zip file and uncompress the data.

The aim of this first class is to get introduce you to R and how it works within RStudio.

In it we will:

1. Work with the Console window to carry out some basic R tasks to familarise with you the software and coding in general.
2. Download a Census data pack from the CDRC Data website
3. Load the data into R using RStudio
4. View the raw data in R
5. Subset data in R
6. Merge data in R

### About R and RStudio 
The statistics and programming language we will be using is called R. It has become an industry standard (along with Python) for interrogating geographical and environmental data  Unlike 'off the shelf' software such as Excel or SPSS, the user has to type commands to get it to execute tasks such as loading in a dataset or performing a calculation. The strength of this approach is that it creates a document, or script, that provides a record of what you have done for everyone to see. It also provide a document that can be reused enabling the straightforward repetition of tasks that create the same result!

It was designed in 1990s for statistics and the generation of publication quality graphics, which can be easily modified and tweaked by making slight changes to the script Command-line computing can be off-putting at first as it is easy to make mistakes that aren’t always obvious to detect. But it is worth sticking with because:

- It is an industry standard with a large user base;
- It’s free and cross-platform so runs on Windows, Mac-OS and Unix
- It is highly customisable with a large number of libraries (‘or packages’) supporting multilevel and longitudinal regression, and mapping, spatial statistics, spatial regression and geostatistics to name a few methods.

R can be downloaded from https://www.r-project.org/ if it is not on your computer already. It is available on our university computer cluster accessible via your AppsAnywhere. There is a shortcut to this on the desktop of all PCs. While it is possible to conduct analysis on R directly, we will run it via Rstudio which provides a user-friendly graphical user interface. After downloading R, Rstudio can be obtained for free from https://www.rstudio.com/.

To open R click on the start menu and open RStudio. You should see a screen resembling the image below (Figure 2). The screen is separated into 4 windows:
- The **scripting window** (top left). This is where you open and edit your scripts (or code files)
- The **console window** (bottom left). This is where R lists the commands you have entered and the results of those commands (or at least some of them)
- The **environment windows** - or if you like R's brain. This window shows the objects held in memory by the system (e.g. datafiles, vectors and so on), as well a history of things you've done, the connections you have open and lastly some tutorial resources.
- The **output/input** window. This shows many things but the most important are the packages you have in the system, the files you are viewing (i.e. where you working directory is), the plots/graphics you might create and help options.

![Figure 2: RStudio screen windows](/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Images/RStudio Screen Grab.png)
We are going to start by setting the ***working directory**. This is so R knows where to open and save files to. It is recommended that you set the working directory to an appropriate space in your computers work space. Make it the directory where you have stored the unzipped data.

To set the working directory, go to the **Session** option from the top bar, click on **Set Working Directory** then **Choose Directory** and use the search window to click through to your directory and select **Open**. 

Alternatively, you can type in the address of the working directory manually using the setwd() function as demonstrated below. This requires you to type in the full address of where your data are stored. **Pay attention to the double quotes around the path address**. 
```{r}
setwd("/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Codefiles/Week 1")
```

If you want to know where your working directory currently is then use the **getwd()** function. R will return the disk address where it is looking.
```{r}
getwd()
```
Or alternatively, if you click on the **Files** tab in the bottom right RStudio window it will show contents of your working directly.

####  Loading some packages into the system
The base installation of R has a lot of packages loaded as default. They sit in the toolbox available for instant use. But some functions are only available in different packages that are not installed in the base R installation. View each package as a run of tools that do things that aren't in the base toolbox. This module will use the **Tidyverse** package for many basic tasks; it includes tools for data manipulation/wrangling, creating graphics, dealing with dates and lots of other things. It was created by Hadley Wickham  and you can read about it here:

https://cran.r-project.org/web/packages/tidyverse/vignettes/paper.html

and here: 

https://doi.org/10.18637/jss.v059.i10

Here is the documentation/manual related to the package:

https://cran.r-project.org/web/packages/tidyverse/tidyverse.pdf

To use packages you must first install them. You can do this by clicking on **packages** on the bottom right window, selecting **install** and searching for the package and installing it. Or if know know the name of the package, you can hard wire the installing using the function install.packages():
```{r}
install.packages("tidyverse") # Note the use of quotes
```
Remember the packages are tools in a toolbox; to use them after you have installed them you need to take them tool out of the box. The function that does this is called **library()**.

```{r}
library(tidyverse) # this loads multiple packages/libraries
```
R will generally manages the conflicts between packages that have functions with the same names but you can tell R use a function from a particular package using the package name, then two colons, and finally the function name. For example:

dplyr::filter().

*Where*, **dplyr** is the package, **::** links the package to the function **filter()**.

#### Your first code / script file
We are going to create a new code file so you can progress through the workshop. The code commands are listed in the html file outlining the workshop activities and **highlighted in square boxes**. To make a new file click on the green cross at the top left of the window -> select 'Script file' from the dropdown list. A new file called **untitled** will be added to the tabs. **Simply copy the text from the boxes and drop it into the scripting window**. Use this area as your workspace rather than typing directly into the console window (bottom left). Change the text below to fit your filename and add today's date. 
```{r}
# Filename: add in your filemane 
# Date: Add a date so you can track changes
```

Hold control Ctrl and enter on your keyboard (command and enter on a mac) to run each line or highlight blocks and do the same. You can also select the line (or block of code) you wish to run and click 'Run' at the top of the scripting window. 

**NOTE: The code is sequential so start at the top and work down. If you miss bits of code it will error and you will get confused and likely frustrated.**

#### Coding Basics
R has a **steep learning curve**, but the benefits of using it are well worth the effort. Take your time and think what the code is doing as you use it. As Wickham *et al*. (2023) note "*Frustration is natural when you start programming in R because it is such a stickler for punctuation, and even one character out of place can cause it to complain. But while you should expect to be a little frustrated, take comfort in that this experience is typical and temporary: it happens to everyone, and the only way to get over it is to keep trying*"

The best way to learn R is to take the basic code provided in the workshops and experiment with changing parameters - such as point type in a graph, line thickness or point colour - ***You cannot break it! Everything is fixable***. Make lots of notes as you go along and if you are getting really frustrated take a break! In many ways this is like learning a language; a little practice more frequently is a good strategy.

R operates by taking instructions, running functions and adding the outcomes of those functions into **objects**. The objects are generated by using the assignment operator:

#### <-

This 'pipes' the outcome of a piece of code into an *object*. 

For example, try the following (copy the text from the box below and paste it into your code file, below the filename and data comment lines):

```{r}
Tutorname <- "Jon" # note the quotes. These tell R it is a string.
```

When you run the code it takes the string **Jon** and adds it to an object called **Tutorname**. This object is then stored in the **Environment** window (top right) (Figure 3).

![Figure 3](/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Images/Object_exampleRStudio.png)

If you just type "Jon" and run that code, it will repeat the name in console window (bottom left).

```{r}
"Jon"  
```
All R statements where you create objects, assignment statements, have the same form:

**object_name <- value**
When reading that code, say “object name gets value” in your head. You will make lots of assignments, and typing <- repetitively is a pain to type. You can save time with RStudio’s keyboard shortcut: Press **Alt** and the **-** (the minus sign) in sequence. This is **Option** plus **-** (the minus sign) on a Mac.

Let's explore some more...
R will do lots of things. It will act like a huge calculator running mathematical calculations

```{r}
1/1000*25 # see the response in the console window (bottom left)
```
or 

```{r}
tan(pi*100) # or
10+20+30 # or 
```
As we have seen above you can add the outcomes of these calculations to an **object**. Keep and eye on the **Environment** window as you run the code. This is useful if you want to use the outcome many times.

```{r}
x <- 8 * 9
```
Notice it doesn't show the content of the **object** in the console window but it does store as an **object** in the computer memory or R's **Environment** (see top right window).

If you want to know whats in the object then type the object name and run the line of code.
```{r}
x
```
And it gives you the answer in the console (bottom left window)

You can combine multiple elements into a vector with the **c()** function (literally stands for 'concatenate' or 'add together'):

```{r}
primes <- c(2, 3, 5, 7, 11, 13) # adds primes from zero to 13 into a vector
```

And basic arithmetic on vectors is applied to every element of of the vector. So here each prime in the sequence is multiplied by 2 and the and returned to the same object. 
```{r}
primes * 2
```

**NOTE R overwrites the previous object with no warnings as that is what you told it to do!**: If want to retain the first object then give the new one a different name!

Let's create some vectors related to the different heights of males and females. Google tells me that on average women are shorter than men. In the USA in 2018 the average height for adult women was 160 cm, whereas for men it was ~ 176 cm. 

```{r}
female <- c(158, 152, 160, 166, 170, 161, 162, 155, 160, 161) # 10 women heights in cm
male <- c(180, 175, 173, 177, 170, 183, 178, 179, 181, 188) # 10 male heights in cm
```

Once we have data stored in this way we can use statistic functions to look at it.

So we can compute averages or the mean height of each:

```{r}
avM <- mean(male)
avF <- mean(female)
avM
avF
```

We can find the tallest in each group
```{r}
tallM <- max(male)
tallF <- max(female)
tallM
tallF
```
#### <span style="color:red;">TASK 1: What do you think the function to find the smallest male and females might be? [~ 1 min]</span>

We can plot calculate how variable they are:

```{r}
sd(male)
sd(female) # notice we haven't created objects so the values are returned to the console window and not stored.
```
R has very many statistical functions and they often group common tasks. So the **summary()** function generates a run of basic statistical metrics for the males.

```{r}
summary(male) #look at the console to see the output
```
#### <span style="color:red;">TASK 1. Repeat this for the females [~ 1 mins]</span>
Now we have the heights of females and males we might want to compare the statistics. We can do this by creating a dataframe from using the heights of females and males and using the same **summary()** function to do that. We start by using the dplyr function **data_frame()** to combined the two vectors into on dataframe called **df**. 
```{r}
df <- dplyr::data_frame(male,female) # notice we are pointing to the package and function here using ::
df # this shows the data in our dataframe
```
Now we can compare them using the **summary()** function: 
```{r}
summary(df)
```
It makes much more sense to use graphics and others statistics (e.g. means tests) to do this sort of comparison. We will pick up on these themes as the module progresses, but right now, lets conclude this session by seeing how to import datasets that already exist in digital forms into R. 

#### Loading data and data formatting in R
One of R’s great strengths is its ability to load in data in many different formats. Comma Separated Value (CSV) files are often a preferred choice for data due to their small file sizes and simplicity, but R can handle tab delineated, xls, SPSS and a number of other data formats. CSVs are a simple means of storing data so that it can be easily read and written on a computer. They are plain text with the fields of data separated by commas (you can observe this if you open a CSV in notepad or some other textfile program). We are going to open four different datasets from the Census database. 

We can read CSVs into R using the read_csv() function as demonstrated below. This requires us to identify the file location within our workspace, and also assign an object name for our data in R. We will return to the datasets you downloaded and unzipped. **Make sure your working directory is pointing to the directory where you unzipped the datafiles**

I am resetting mine to the right place. I am doing it manually as show above. The copying the code from the console window showing the path and adding in the name of the csv file.

```{r}
# loads a csv, remember to correctly input the file location within your working directory or point to the directory where you data are stored.

Ethnicity <- read_csv("/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Data/Birmingham Census 2021 MSOA/TS021 - Ethnic group.csv")

Rooms <- read_csv("/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Data/Birmingham Census 2021 MSOA/TS053 - Occupancy Rating.csv")

Qualifications <-read_csv("/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Data/Birmingham Census 2021 MSOA/TS067 - Highest level of qualification.csv")

Employment <-read_csv("/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Data/Birmingham Census 2021 MSOA/TS066 - Economic activity status.csv")
```
#### Viewing data
With the data now loaded into RStudio, they can be observed in the objects window. Alternatively, you can open them with the **View()** function as demonstrated below. Note the capital 'V' in function name. This is used because View() is a function created by RStudio. R functions always have a lower case starting letter. Adding a capital letter will make the function error and return a 'name not recognised' outcome.

```{r}
# to view the top 1000 cases of a data frame
View(Qualifications)
```
All functions need a series of arguments to be passed to them in order to work. These arguments are typed within the brackets and typically comprise the name of the object that contains the data followed by some parameters. The exact parameters required are listed in the functions’ help files. To find the help file for the function type ? followed by the function name, for example - ?View

You can used a run of other function to gain an understanding of the data.
```{r}
dim(Qualifications) # will return the dimensions of the data file, listing the number of rows first then the number of columns.
```
We can see that employment dataframe has 1443 rows and 19 columns. 

```{r}
head(Qualifications) # will list the first few lines of data
```
Shows the first few lines of data

```{r}
tail(Qualifications) # will [have a guess what this returns!]
```

```{r}
str(Qualifications) # shows the data structure.
```

Of all of these function str() is a very important one as it shows us the key elements of the data. You can also use ***glimpse()** from the tidyverse package to do a similar thing. R stores data in different **classes**; these classes are shown in the output created by both functions either **str()** or **glimpse**. 

Here are a few of the most important ones:

 - Double/decimal data - continuous data with decimal points
 - Integers - whole numbers 
 - Factors - for variables that have a fixed and known set of possible values
 - Strings - for adding, displaying and using text data
 - Vectors - combinations of individual variables of data items
 - Dataframes - equivalent in many ways to a excel sheet in a spreadsheet
 
It is important to be aware of this as R handles these different **classes** of data differently. You need not worry about this at the moment but its importance will become evident as the workshops progress. There are lots of other classes for spatial data, lists, matrices and so on. We will introduce them to you on *a needs to know basis*, so as to reduce the information overload. 

So, returning to our imported data. There are two problems with the data. Firstly, the column headers, although very informative,  are too long for repeated typing while we are coding. Secondly, the data we are interested in is split between four dataframes each with many columns.

#### Observing column names
First, we need to find the columns we are interested in. These are shown in Table 1 below.

![Table 1: Key data columns](/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Images/Table_for_columns.png)

To observe the column names for each dataset we can use the **names()** function. It is also possible to work out their order in the columns from observing the results of this function because each column is numbered sequentially in the dataframe. We will add the results to a vector that we can print later.

Starting with ethnicity
```{r}
Colnames_Ethnicity <- names(Ethnicity) # 52 Columns
```

Rooms...
```{r}
Colnames_Rooms <- names(Rooms) # 14 columns
```

Qualifications....
```{r}
# view column names of a dataframe
Colnames_Qualifications <- names(Qualifications) # there are 19 columns. A combination of values and % data
```

Employment data...
```{r}
Colnames_Employment <- names(Employment) # 64 columns
```

We have added the column names into four objects. The first one was **Colnames_Ethnicity**. If we look at it: 
```{r}
print(Colnames_Ethnicity)
```
And refer to the table above we need column 38 which is "% White: English, Welsh, Scottish, Northern Irish or British".

#### <span style="color:red;">Task 2: Use the **print()** function to find the other column names/numbers from the Rooms, Qualifications and Employment dataframes. Make a note of the numbers you need them shortly! [~ 5mins]</span>

#### Selecting columns
Next, we will create new data objects which only include the columns we require. The new data dataframes will be given the same name as the original ones so they will overwrite the previous versions. We are downloading percentages, not raw counts, because the MSOAs are have different numbers of people in them (see MSOA desciption above). You already know what columns you need (see Table 1 above) and we call them using the [] (square brackets) which allow us to subset the data. So it works like this:

Dataframe_name[first element are the rows, second element are the columns]. 

**In R rows always come first before columns**. The comma '**,**' separates the rows from the columns. To access the correct bits of data we use the row and column numbers not names (there are ways to use names and we'll come to that as the course progresses). 

An example:
Ethnicity[, c(2, 38)] 

Notice that: 
 - The dataframe = Ethnicity
 - There is not a number before the comma and this means we want all the rows
 - We use c(2, 38) after the comma, which means we want all the rows from columns 2 and 38, or put another all the data from columns 2 and 38. 
Column 2 (Geog_Code) is repeated in all 4 dataframes as it is the unique identifier (or code) for all 132 of Birmingham's mid level super output areas (MSOAs).
Columns 38 holds the % data for % White: English, Welsh, Scottish, Northern Irish or British people census.

#### <span style="color:red;">TASK 3: Fill in the correct column number for the other dataframes below [~ 5 mins]</span>

```{r}
# selecting specific columns only
# note this action overwrites the labels you made for the original data, 
# so if you make a mistake you will need to reload the data into R
Ethnicity <- Ethnicity[, c(2, 'add the column number')] #% White: English, Welsh, Scottish, Northern Irish or British
Rooms <- Rooms[, c(2, 'add the column number')] #
Employment <- Employment[, c(2, 'add the column number')] # % Economically active (excluding full-time students): Unemployed   
Qualifications <- Qualifications[, c(2, 'add the column number')] # % Level 4 qualifications or above
```


```{r include=FALSE}
# selecting specific columns only
# note this action overwrites the labels you made for the original data, 
# so if you make a mistake you will need to reload the data into R
Ethnicity <- Ethnicity[, c(2, 38)] #% White: English, Welsh, Scottish, Northern Irish or British
Rooms <- Rooms[, c(2, 14)] #
Employment <- Employment[, c(2, 28)] # % Economically active (excluding full-time students): Unemployed   
Qualifications <- Qualifications[, c(2, 16)] # % Level 4 qualifications or above
```
#### Renaming column headers
Next we want to change the names of the columns to ease our interpretation and reduce the amount of typing we need to do! We can do this using the names().

If we wanted to change an individual column name we use the approach shown below. Here we are asking R to use the dataframe called 'Ethnicity' and changing column name 2 to "White_British". Notice that we don't need the comma **','** in the square brackets as the **names()** function is expecting columns. We can use ***rownames()** to change or set row names if necessary.
```{r}
# to change an individual column name
names(Ethnicity)[2] <- "White_British"
```
However, we want to name both column headers in all our dataframes. To do this we use c() function to concatenate multiple values within one command.
```{r}
# to change both column names
names(Ethnicity)<- c("Code", "White_British")
names(Rooms)<- c("Code", "Low_Occupancy")
names(Employment)<- c("Code", "Unemployed")
names(Qualifications)<- c("Code", "Qualification")
```
R offers many functions that do the same thing. So, for example, you can also use **col_names = c("Code", "White_British")** to do the same thing. This is a tidyverse function. The base R equivalent is **colnames()**. I appreciate this confusing. Find one you like and stick with it! **Keep it simple and consistent**.

#### Joining data in R
Our last job is to combine the data into a single dataframe. Joining two data frames together requires a common field, or column, between them. In this case, it is the **Code** column. In this column each row has a unique ID (or Output Area name), that identifies each output area in each of the datasets; these effectively link the datasets together. In R the merge() function joins two datasets together and creates a new object. As we are seeking to join four datasets we need to undertake multiple steps as follows:
```{r}
#1 Merge Ethnicity and Rooms to create a new object called "merged_data_1"
merged_data_1 <- merge(Ethnicity, Rooms, by="Code")
#2 Merge the "merged_data_1" object with Employment to create a new merged data object
merged_data_2 <- merge(merged_data_1, Employment, by="Code")
#3 Merge the "merged_data_2" object with Qualifications to create a new data object
Census.Data <- merge(merged_data_2, Qualifications, by="Code")
#4 Remove the "merged_data" objects as we won't need them anymore
rm(merged_data_1, merged_data_2)
```
Our newly formed Census.Data object contains all four variables and the a Code column with all 132 unique MSOA codes for the City of Birmingham.

#### Exporting Data
You can now save this file to your workspace folder. We will use thesr data in the next couple of practicals. To save the data we use the ***write.csv()** function. We do not need row numbers (the numbers on the left of the data - see in th View window) so add **row.names=F**. We will save the data as practical_data.csv to our working directory. Remember R is case sensitive so take note of when object names are capitalised. **All we have done here is take the Census.Data dataframe and save it to a CSV file (called practical_data.csv) for use in the next workshop.**
```{r}
# Writes the data to a csv named "practical_data" in your file directory
write.csv(Census.Data, "/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Data/Birmingham Census 2021 MSOA/practical_data.csv", row.names=F)
```
### What's next?
Next week will we use the same data set to introduce you how to start to explore data and understand its patterns and dependencies. This is a crucial and important **first step** before you start to analyse data. You will be developing this skill consistently through the module.

### Follow up work
Please read the documents linked to above (i.e. tidyverse and tiday data links) if you didn't do so in the session **AND** then the chapter 2 ("Workflow Basics") in:

Hadley Wickham, Mine Cetinkaya-Rundel, Garrett Grolemund (2023) *R for Data Science: Import, Tidy, Transform, Visualize, and Model Data* (2nd Ed). O'Reilly. It is freely available here:

https://r4ds.hadley.nz/

I encourage you also to play with the code and exercises too!

### Appendix

Here are the explanations of the census categories for data we have downloaded from the https://www.nomisweb.co.uk/ data portal.

![UK census 2021 Ethnicity data](/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Images/Ethnicity_explanation.png)

![UK census 2021 Household occupancy data](/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Images/Occupancy_explanation.png)

![UK census 2021 Economic Activity data](/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Images/EconomicActitiy_explanation.png)

![UK census 2021 Educational Level data](/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Images/EducationLevel_explanation.png)

----
Jon Sadler Oct 2024