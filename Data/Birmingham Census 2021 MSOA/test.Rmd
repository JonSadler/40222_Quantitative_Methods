---
title: "Data exploration strategies using R"
subtitle: "Week 2"
output: html_notebook
---
#### Outline of the session
This week our focus is on data visualisation and exploration. To do this
we will use graphical techniques that visualize and transform to explore
data in a systematic way, a task that statisticians call **exploratory
data analysis**, or EDA for short. EDA is an iterative cycle, where you:

-   Generate questions about your data.
-   Search for answers by visualizing, transforming, and modelling your
    data.

It is a key part of the important task of communicating your findings to
the wider world in a clear and reproducible manner (Figure 2).

**Figure 1:** The data analysis cycle

We going to use the dataset you created at the end of the last workshop,
supplement by some data that are available in the base R and tidyverse
applications. The aim is to use the ggplot2 package to do this work and
we will use a range of different types of graphs to illustrate how to
represent data structure and the relationship between columns of data in
our dataframes.

Data exploration is an important and integral part of data analysis. If
you read around this you will find that people suggest it is appropriate
to spend ~ 50% of your analytical time engaged in exploring your
datasets to identify (sometimes hidden) issues. This is key to
highlighting:

1.  The variation in the data;
2.  Possible typological / recording issues in the data;
3.  The presence of influential and extreme points - sometimes termed
    'outliers';
4.  But also hidden data dependencies in the data that Iimit how it
    might be used.

show you how to use visualization and transformation to explore your
data in a systematic way, a task that statisticians call exploratory
data analysis, or EDA for short. EDA is an iterative cycle. You:

Generate questions about your data.

Search for answers by visualizing, transforming, and modelling your
data.

Use what you learn to refine your questions and/or generate new
questions. Specifically in this workshop we will:

***Session Aim**
To understand the importance of data visualisation for data analysis.

**Learning Outcomes**
At the end of this workshop your will be able to use the **ggplot2**
package for data visualisation with a range of types of graphics to
examine your data in terms of:

-   Comparisons of variables
-   Examining data distributions and frequencies
-   Finding associations between variables
-   Identifying potential outliers
-   Investigation potential data dependencies
-   Creating high quality graphics

**Maxim of the day “Don’t start data analysis without exploring the data
(graphically) first”**

#### Some words about ggplot2 (from the tidyverse package)
We are going to use **ggplot2** for all our plotting in this module
unless it is more difficult to do so (i.e. GIS type functions). As I
mentioned R was created to generate excellent graphic so the functions
in base R to this are extensive. My decision to use **ggplot2** is base
on its clear graphical structure or as Wickham et al. might say, **its
grammar of graphics**. There is a whole book dedicated to this:

Wickham, H., Gentleman, R., Hornick, K. & Parmigiani, G. (2009)
*ggplot2: Elegant Graphics for Data Analysis*. Springer. New York.

The third updated edition is freely available here should you wish to
read it: <https://ggplot2-book.org/>

It works by layering up components as shown below in Figure 2. This is a
screenshot from Wickham et al. (2024) i.e. the book list in the URL
above. The text describes the elements better than I could.

**Figure 2:** ggplot2 core structural elements

**Do not stress if this all appears impenetrable. We will unpack it in
today's workshop and reinforce your understanding in subsequent sessions
as the module progresses**. So let's make a start on today's activities.

#### Things to do at the start of each session

1.  **Set your working directory**. Note RStudio can save your working
    environment so you may already have that in hand from the last
    session i.e. the WD might be correct. If not either set it manually
    by clicking on the **Session** option from the top bar, click on
    **Set Working Directory** then **Choose Directory** and use the
    search window to click through to your directory and select
    **Open**. Alternatively, you can type in the address of the working
    directory manually using the setwd() function as demonstrated below.
    This requires you to type in the full address of where your data are
    stored. **Pay attention to the double quotes around the path
    address**.

```{r}
setwd("/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Codefiles/Week 2")
```

2.  **Load the packages** that you want to use. In this session we only
    need the **tidyverse** package. We'll be installing many more as the
    sessions progress so the list will increase in size.

```{r}
library("tidyverse") # don't forget to use the quote marks!
```

3.  Find the dataset from last week. Recall it was named
    "practical_data.csv". When you saved it, the file would have been
    put in the work directory which was live at that point. So depending
    on how you organised things, it'll likely be in directory called
    'Week 1' or something similar. To keep things tidy I tend to
    organise my file structure in a manner that separates codefiles from
    the datafiles. I put all my codefiles in directory called
    'Codefiles' and within that I create weekly subdirectories (e.g.
    'Week 1', 'Week 2' etc). I stored the codefile/script in those
    weekly directories and set them each week as my working directory.
    Then any graphics, datafiles I save from R gets automatically stored
    in the correct weekly directly. To load the data in, I code that
    directly using the **setwd()** function. Figure 3 (below) shows a
    screenshot of this structure. **You need to figure out a strategy
    that works for you**.


**Figure 3:** Jon's directory structure

4.  **Create your new script by new file clicking on the green cross at
    the top left of the window -\> selecting 'Script file' from the
    dropdown list.** A new file called **untitled** will be added to the
    tabs. Click on the tab and then blue disk icon to save the file.
    Note that it will be saved to your current working directory, so
    make sure you are happy with that location. Give it a name that is
    meaningful to you. I name mine with module code and then week number
    (e.g. LM40222_Week_1.Rmd). Note that I use R notebooks to create the
    html documents for these classes so the file extension (or suffix if
    you like) is **Rmd**. You are creating scripts so their extension
    will be **.R**.

#### Today's session

Let's starting by loading at your dataset. Mine is now located in my
data directory -\> in the Birmingham Census 2021 MSOA subdirectory. I am
going to load it directly from there using the appropriate path (it's
long so I am setting my WD to there manually as described above, copying
the path using **getwd()** and adding the path and file name to my
**read_csv()** function call:

```{r}
BhamData <- read_csv("/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Data/Birmingham Census 2021 MSOA/practical_data.csv")
```

I called the imported data **BhamData** you can call it whatever you
want but as we progress remember where my code states **BhamData** you
need to replace it with **your dataframe name** if you called it
something else! We need to revisit the structure of the data before we
start plotting things.

```{r}
glimpse(BhamData)
```

We can see that dataset has 132 rows which are the 132 mid layer super
output areas in the City of Birmingham and 5 columns (see last week's
Appendix for full descriptions of the data metadata/explanations):

-   Code - the unique MSOA codes
-   White_British which is the % of people who are white and British
-   Low_Occupancy which is % of people living in very overcrowded
    accommodation where there are not enough bedrooms that meet statuory
    guidance
-   Unemployed which is the % of people of working (that aren't
    students) who are unemployed
-   Qualification which is % of people with higher level qualifications
    (i.e. effectively post school qualifications)

We can also see that the data type are double (i.e. decimal) as shown by
<dbl> adjacent to column 2,3,4, and 5, but column 1 (i.e. **Code**) is
shown as <chr> meaning it is a character data class. R will use this a
factor in our analyses for many statistical functions but not all, so we
need to remember that! Recall also that the data we are using are all
percentages so we don't want to see any numbers larger than 100! We can
check by using the **summary()** function.

```{r}
summary(BhamData)
```

Examining the Max data we see all are less than 100%. It also shows us
other important things such as: - the proportion of unemployment was low
with a max of 9% being the largest value in an MSOA - on average only
30% of the population across the MSOAs had a higher level educational
qualification - etc etc

#### Data Visualisation - Creating ypour first ggplot

We are going to start by walking you through the steps to create an
image. It will be a complex journey but you don't have to understand
everything to start with. **Don't panic**. What we are doing is
replicating Chapter 1 in <https://r4ds.hadley.nz/data-visualize> called
**Data Visualisation** but using our data.

##### Our ultimate goal


**Figure 4:** This is our goal graphic we are going to recreate

We'll recreate this plot step-by-step. To begin with we use the function
ggplot(), defining a plot object that you then add layers to. The first
argument of ggplot() is the dataset to use in the graph and so\*
**ggplot(data = BhamData)**. This creates our blank canvas which we
layer things onto.

```{r}
ggplot(data = BhamData) # when run it we get a grey box in plot window (bottom left)
```

Next up we add in the mapping argument of the **ggplot()** function.
This defines which variable in our dataset we are to map and also to
visual properties (**aesthetics**) of your plot. The mapping argument
uses **aes()** function, and the x and y arguments of **aes()** tell
ggplot which variables to map to the x and y axes. To start with we go
for using the \# Unemployed on the X axis and the % with higher level
qualifications on Y. Notice R (via ggplot uses the column names as
labels on x anx Y). We can of course change this and modifiy the lines,
fonts etc.

```{r}
ggplot(
  data = BhamData,
  mapping = aes(x = Unemployed, y = Qualification)
)
```

You can see it has created the canvas for the plot but the data points
are missing. We add these by selecting a **geom**: the geometrical
object that a plot uses to represent data. All geometric objects in
ggplot2 start with **geom\_**. People often describe plots by the type
of geom that the plot uses. For example, bar charts use bar geoms
**(geom_bar())**, line charts use line geoms **(geom_line())**, boxplots
use boxplot geoms **(geom_boxplot())**, scatterplots use point geoms
**(geom_point())**, and so on. Because we are displaying two variables
as an XY plot we use **(geom_point())**.

```{r}
ggplot(
  data = BhamData,
  mapping = aes(x = Unemployed, y = Qualification)
) + geom_point()
```

Now we have a scatterplot that shows our data points. If you count them
you'll find 132 points which relate to the 132 MSOAs in our data which
also is the number of rows in the dataset.

#### [TASK 1: What does this tell us about the relationship between unemployed people and their eductional level [\~ 5 min]]{style="color:red;"}

Remember there are four data sources of data for each individual dot (or
MSOA), we are displaying just two of them. As a result, this plot does
not represent a full depiction on the relationships between the
variables. How, for example, are the levels of education and
unemployment affected by ethnicity or household overcrowding? To achieve
this we need to modify the **aes()** of the **geom**.

```{r}
ggplot(
  data = BhamData,
  mapping = aes(x = Unemployed, y = Qualification, colour=White_British)
) + geom_point()
```

This adds a further layer onto the plot where the % of white British
residents is mapped. When a continuous variable is mapped to an
aesthetic, ggplot2 automatically assigns a graded value to the aesthetic
(here a graded blue color by default). It operates slight differently
with a categorical variable (see your follow on work below!)

We can invert the colours so darker colours represent MSOAs with higher
proportions of white British residents using and we can also change the
colour to red.

```{r}
ggplot(
  data = BhamData,
  mapping = aes(x = Unemployed, y = Qualification, colour = White_British)
) +
  geom_point() +
  scale_colour_gradient(low = "red", high = "darkred")

```

#### [TASK 2: How does ethnicity linked unemployment and educational levels? [\~ 5 min]]{style="color:red;"}

It isn't the clearest of patterns. If we move our colour **aes()** from
the *global* aesthetic and add to the **geom**, then we can use size and
colour to represent the proportion of White_British in the populations
of MSOAs.

```{r}
ggplot(
  data = BhamData,
  mapping = aes(x = Unemployed, y = Qualification)
) +
  geom_point(aes(size = White_British, colour = White_British)) +
  scale_colour_gradient(low = "red", high = "darkred") 
```

This is helps clarify a noisy picture! What do you think?

Lastly to depict the shape of the relationship we can add a 'best fit'
line through the data. We do this by adding new **geom** as a layer on
top of our point geom: using **geom_smooth()**. And we will specify that
we want to draw the line of best fit based on a linear model with method
= **"lm"**.

```{r}
ggplot(
  data = BhamData,
  mapping = aes(x = Unemployed, y = Qualification)
) +
  geom_point(aes(size = White_British, colour = White_British)) +
  scale_colour_gradient(low = "red", high = "darkred") +
  geom_smooth(method = "lm")
```

ggplot automatically fits a straightline to the data and plots the 95%
confidence intervals (CIs) around the line. Notice that the width of CIs
increases where there are fewer data points. Well discuss why these
things happen later in the module. We probably should change the line
colopur to red by adding **colour=red** to **geom_smooth()** function.

```{r}
ggplot(data = BhamData, mapping = aes(x = Unemployed, y = Qualification)) +
  geom_point(aes(size = White_British, colour = White_British)) +
  scale_colour_gradient(low = "red", high = "darkred") +
  geom_smooth(method = "lm", color = "red")
```

Looks a bit more like the figure we were aiming at. We finalise it by
adding new labels for the axes, legends and a title using the **labs()**
function.

```{r}
ggplot(data = BhamData, mapping = aes(x = Unemployed, y = Qualification)) +
  geom_point(aes(size = White_British, colour = White_British)) +
  scale_colour_gradient(low = "red", high = "darkred") +
  geom_smooth(method = "lm", color = "red") +
  labs(
    title = "Educational attainment and unemployment levels in Birmingham",
    subtitle = "Links to ethnicity",
    x = "Resident Unemployment (%)", y = "Residents education  (% level 4 or above)",
    color = "White British (%)", size = "White British (%)"
  )
```

We now have the plot. It could be further improved but are happy with it
for now so we save it. You can do this manually using the **export**
option in **Plots** the output/input window bottom right) or code it
directly. I want it in my codefiles directory so I direct it there.
**Your paths will differ so you need to amend the code accordingly**. To
do this we just pipe the plot into and object.

```{r}
BhamPlot <- ggplot(data = BhamData, mapping = aes(x = Unemployed, y = Qualification)) +
  geom_point(aes(size = White_British, colour = White_British)) +
  scale_colour_gradient(low = "red", high = "darkred") +
  geom_smooth(method = "lm", color = "red") +
  labs(
    title = "Educational attainment and unemployment levels in Birmingham",
    subtitle = "Links to ethnicity",
    x = "Resident Unemployment (%)", y = "Residents education  (% level 4 or above)",
    color = "White British (%)", size = "White British (%)"
  )
```

And save it is using the **ggsave()** function, setting the parameters
we need.

```{r}
ggsave(
  filename = "/Users/jonsadler/Library/CloudStorage/OneDrive-UniversityofBirmingham/Teaching-materials/COURSES/4TH_YR/LM 40222 Quantitative methods/Codefiles/Week 2/BhamPlot.jpg", 
  plot = BhamPlot,  # Remove the quotes around BhamPlot
  width = 12, 
  height = 10, 
  dpi = 300, 
  units = "cm"
)
```

#### Data exploration
We will start by considering how we can visualise distributions in data.
How we do this depends on the type of variable: categorical or
numerical. - A variable is categorical if it can only take one of a
small set of values. To examine the distribution of a categorical
variable, you can use a bar chart. The height of the bars displays how
many observations occurred with each x value. - A variable is numerical
(or quantitative) if it can take on a wide range of numerical values,
and it is sensible to add, subtract, or take averages with those values.
Numerical variables can be continuous or discrete.

We know from looking at the structure of our data that it is numerical;
remember <dbl> categorization when we used **glimpse** to look at the
data? To exaine the distribution of these types of data we use
**geom_histogram**. Notice here that we are shorting the ggplot code by
adding the aesthetics to the ggplot() call and dropping out some of the
other commands (e.g. mapping etc)

```{r}
ggplot(BhamData, aes(x = Qualification)) +
  geom_histogram(binwidth = 10)
```

Urgh this looks ugly. This is because we have percentage data so to see
the full range we need to increase the number of bins to say 1 (gives us
a maximum of 100).

```{r}
ggplot(BhamData, aes(x = Qualification)) +
  geom_histogram(binwidth = 1)
```

Maybe a little too many but it does indicate there might be a few
extreme points in our data at the top end of MSOAs for educational
outcomes. Perhaps 5 would close off the gaps.

```{r}
ggplot(BhamData, aes(x = Qualification)) +
  geom_histogram(binwidth = 5)
```

This looks better. We can see from this that the data not normally
distributed as they are clumped (or skewed at the bottom end of the
distribution centred around 25).

Although they show fewer details than a histogram they are useful for
understanding the shape of a distribution and make it easier to
'see' the shape of the distribution, particularly with respect to modes
and skewness. We can see these data are very skewed to the right. Yes I
know the lump is on the left! But see:



Like all geoms you can add different aesthetics to change line colour,
line widths and so on and also add labels etc. Have a read about them:
<https://ggplot2.tidyverse.org/reference/geom_density.html>

### Follow on work

Read chapter 1 of <https://r4ds.hadley.nz/data-visualize> which we
replicated with our plotting exercise today. Try completing Exercises
1-5 or more if you are coping well with the work!

Jon Sadler Oct 2024
